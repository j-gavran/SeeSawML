Training is handled by PyTorch Lightning's [`Trainer`](https://lightning.ai/docs/pytorch/stable/common/trainer.html) class, which provides a high-level interface for training models. The training configuration options are specified in the `experiment_config` field of the `training_config.yaml` files. Training is performed by running `train_signal` or `train_fakes` commands.

## Available Configuration Options

- `experiment_name: str`: Name of the training experiment. Used for logging and checkpointing.
- `run_name: str | None`: Optional name for the specific training run. If not provided, a default name based on timestamp will be used.
- `save_dir: str | None`: Directory where to save model checkpoints and logs. If set to `null`, defaults to `ANALYSIS_ML_LOGS_DIR`.
- `tracker_path: str | None`: Path for the experiment tracker (i.e., plotting when training). If set to `null`, defaults to `ANALYSIS_ML_RESULTS_DIR`.
- `seed: int | None`: Random seed for reproducibility. If set to `null`, no seed is set.
- `accelerator: str`: Accelerator to use for training. Options are `cpu`, `gpu`, or `auto`.
- `devices: int | list[int] | str`: Number of devices to train on (`int`), list of devices (`list[int]` or `str`), or `auto`.
- `precision: int | str`: Double precision (`64` or `64-true`), full precision (`32` or `32-true`), 16bit mixed precision (`16` or `16-mixed`) or bfloat16 mixed precision (`bf16` or `bf16-mixed`).
- `float32_matmul_precision: str`: Precision for float32 matrix multiplications. Options are `highest`, `high`, or `medium`. See [PyTorch docs](https://docs.pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html) for more details.
- `comet_api_key: str | None`: Comet API key for experiment tracking. If set to `null`, Comet tracking is disabled.
- `comet_project_name: str | None`: Comet project name for experiment tracking. If set to `null`, uses default project.
- `log_every_n_steps: int`: Frequency (in steps) to log training metrics.
- `check_eval_n_epoch: int`: Frequency (in epochs) to run evaluation on the validation set.
- `num_sanity_val_steps: int`: Number of validation steps to run before training to catch bugs.
- `check_metrics_n_epoch: int`: Frequency (in epochs) to compute tracker metrics.
- `plot_metrics_n_epoch: int`: Frequency (in epochs) to plot tracker metrics.
- `tqdm_refresh_rate: int`: Refresh rate for the TQDM progress bar.

!!! Note
    If running locally and not on a cluster, it is recommended to use MLFlow for experiment tracking instead of Comet. This can be set by omitting the `comet_api_key` and `comet_project_name` fields in the configuration or setting them to `null`.

!!! Tip
    MLFlow can be launched locally by running `track -p <port_number>` in a terminal and then accessing the UI at `http://localhost:<port_number>` in a web browser. All training runs will be logged automatically to the `mlruns/` directory inside `ANALYSIS_ML_LOGS_DIR`.

!!! Info
    SeeSawML supports plotting of model performance and custom metrics on validation set during training. This is handled by the internal [`Tracker`](https://seesawml.docs.cern.ch/api/models/training/#seesaw.models.tracker.Tracker) class. If using MLFlow the plots can be viewed in the MLFlow UI under the "Artifacts" section. Note that plotting during training may slow down the training process and leak memory if too many plots are generated by matplotlib. It is recommended to set `plot_metrics_n_epoch` to reasonable values (e.g., every 5 or 10 epochs or even disable it by setting it to `null`) to avoid excessive plotting.
